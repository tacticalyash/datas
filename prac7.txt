prac 7 - tokenization , pos tagging , stop words removal


import nltk
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('averaged_perceptron_tagger')
nltk.download('omw-1.4')

text="Hello. How are you?"

from nltk.tokenize import sent_tokenize
tokenized_text=sent_tokenize(text)

tokenized_text

from nltk.tokenize import word_tokenize
tokenized_word=word_tokenize(text)
tokenized_word

from nltk.corpus import stopwords
stop_words=set(stopwords.words("english"))
stop_words

wordsFiltered = []
for w in tokenized_word:
 if w not in stop_words:
 wordsFiltered.append(w)
print(wordsFiltered)


from nltk.stem import PorterStemmer
words = ["game","gaming","gamed","games"]
ps = PorterStemmer()
for word in words:
 print(ps.stem(word))


from nltk.stem import WordNetLemmatizer
wordnet_lemmatizer = WordNetLemmatizer()
text1 = "studies studying cries cry"
tokenization = nltk.word_tokenize(text1)
for w in tokenization:
 print("Lemma for {} is {}".format(w,wordnet_lemmatizer.lemmatize(w)))


for word in tokenized_word:
 print(nltk.pos_tag([word]

import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer

documentA = 'Jupiter is the largest Planet'
documentB = 'Mars is the fourth planet from the Sun

bagOfWordsA = documentA.split(' ')
bagOfWordsB = documentB.split(' ')

bagOfWordsA

uniqueWords = set(bagOfWordsA).union(set(bagOfWordsB))

uniqueWords

numOfWordsA = dict.fromkeys(uniqueWords, 0)
for word in bagOfWordsA:
 numOfWordsA[word] += 1
numOfWordsB = dict.fromkeys(uniqueWords, 0)
for word in bagOfWordsB:
 numOfWordsB[word] += 1

numOfWordsA

numOfWordsB

def computeTF(wordDict, bagOfWords):
 tfDict = {}
 bagOfWordsCount = len(bagOfWords)
 for word, count in wordDict.items():
 tfDict[word] = count / float(bagOfWordsCount)
 return tfDict
tfA = computeTF(numOfWordsA, bagOfWordsA)
tfB = computeTF(numOfWordsB, bagOfWordsB)

tfA


def computeIDF(documents):
 import math
 N = len(documents)
 idfDict = dict.fromkeys(documents[0].keys(), 0)
 for document in documents:
 for word, val in document.items():
 if val > 0:
 idfDict[word] += 1
 for word, val in idfDict.items():
 idfDict[word] = math.log(N / float(val))
 return idfDict
idfs = computeIDF([numOfWordsA, numOfWordsB])
idfs


def computeTFIDF(tfBagOfWords, idfs):
 tfidf = {}
 for word, val in tfBagOfWords.items():
 tfidf[word] = val * idfs[word]
 return tfidf


tfidfA = computeTFIDF(tfA, idfs)
tfidfB = computeTFIDF(tfB, idfs)
df = pd.DataFrame([tfidfA, tfidfB])
df
